{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf8126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import io\n",
    "import math\n",
    "import time\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "\n",
    "import gradio as gr\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pyroomacoustics as pra\n",
    "import soundfile as sf\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "\n",
    "# Usar backend 'Agg' para evitar que las figuras se muestren en el notebook directamente\n",
    "# ya que las convertiremos a im√°genes para Gradio.\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59c574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Ubicaciones y constantes globales\n",
    "# -----------------------------------------------------------------------------\n",
    "# En un notebook, usamos el directorio actual de trabajo\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "INPUTS_DIR = DATA_DIR / \"inputs\"\n",
    "OUTPUTS_DIR = DATA_DIR / \"outputs\"\n",
    "\n",
    "# Crear directorios si no existen\n",
    "INPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE_OPTIONS = [48_000, 44_100]\n",
    "INPUT_OPTIONS = [\n",
    "    \"Aplauso sint√©tico\",\n",
    "    \"Barrido senoidal (20 Hz ‚Äì 12 kHz)\",\n",
    "    \"Subir un audio WAV/FLAC/MP3\",\n",
    "]\n",
    "\n",
    "FILTER_MAP = {\n",
    "    \"Ninguno\": \"none\",\n",
    "    \"Pasa-bajos\": \"lowpass\",\n",
    "    \"Pasa-altos\": \"highpass\",\n",
    "    \"Pasa-banda\": \"bandpass\",\n",
    "}\n",
    "\n",
    "IR_PRESETS = {\n",
    "    \"Sala peque√±a\": {\n",
    "        \"type\": \"room\",\n",
    "        \"color\": \"#A23B72\",\n",
    "        \"description\": \"Sala 4√ó3√ó2.5 m, absorci√≥n media-alta.\",\n",
    "        \"params\": {\n",
    "            \"room_dim\": (4.0, 3.0, 2.5),\n",
    "            \"absorption\": 0.45,\n",
    "            \"max_order\": 8,\n",
    "            \"src_pos\": (1.2, 1.0, 1.2),\n",
    "            \"mic_pos\": (3.2, 1.8, 1.2),\n",
    "            \"ir_length_s\": 1.0,\n",
    "        },\n",
    "    },\n",
    "    \"Sala mediana\": {\n",
    "        \"type\": \"room\",\n",
    "        \"color\": \"#F18F01\",\n",
    "        \"description\": \"Sala 8√ó5.5√ó3.2 m, absorci√≥n intermedia.\",\n",
    "        \"params\": {\n",
    "            \"room_dim\": (8.0, 5.5, 3.2),\n",
    "            \"absorption\": 0.25,\n",
    "            \"max_order\": 12,\n",
    "            \"src_pos\": (2.0, 2.3, 1.5),\n",
    "            \"mic_pos\": (6.0, 3.1, 1.5),\n",
    "            \"ir_length_s\": 1.2,\n",
    "        },\n",
    "    },\n",
    "    \"Sala grande / Hall\": {\n",
    "        \"type\": \"room\",\n",
    "        \"color\": \"#C73E1D\",\n",
    "        \"description\": \"Hall 16√ó11√ó6 m, cola larga y brillante.\",\n",
    "        \"params\": {\n",
    "            \"room_dim\": (16.0, 11.0, 6.0),\n",
    "            \"absorption\": 0.12,\n",
    "            \"max_order\": 15,\n",
    "            \"src_pos\": (4.0, 3.0, 2.0),\n",
    "            \"mic_pos\": (12.0, 7.0, 2.5),\n",
    "            \"ir_length_s\": 1.6,\n",
    "        },\n",
    "    },\n",
    "    \"Pir√°mide (Quetzal) üå™Ô∏è\": {\n",
    "        \"type\": \"stepped\",\n",
    "        \"color\": \"#2E86AB\",\n",
    "        \"description\": \"Modelo geom√©trico de escalinata (Kukulk√°n) afinado para que el eco suene como el quetzal (~0.8‚Äì1 kHz).\",\n",
    "        \"params\": {\n",
    "            \"step_height_m\": 0.26,\n",
    "            \"step_depth_m\": 0.18,\n",
    "            \"num_steps\": 91,\n",
    "            \"listener_distance_m\": 8.5,\n",
    "            \"step_reflection\": 0.985,\n",
    "            \"distance_rolloff\": 1.05,\n",
    "            \"extra_decay_db_per_step\": 0.02,\n",
    "            \"jitter_ms\": 0.25,\n",
    "            \"air_lowpass_hz\": 6_500.0,\n",
    "            \"ir_length_s\": 0.50,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ea1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Utilidades de audio y DSP\n",
    "# -----------------------------------------------------------------------------\n",
    "def normalize_audio(x: np.ndarray, peak: float = 0.98) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    max_val = np.max(np.abs(x)) + 1e-12\n",
    "    return (x / max_val) * peak\n",
    "\n",
    "\n",
    "def resample_audio(x: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:\n",
    "    if orig_sr == target_sr:\n",
    "        return np.asarray(x, dtype=float)\n",
    "    g = math.gcd(int(orig_sr), int(target_sr))\n",
    "    up = target_sr // g\n",
    "    down = orig_sr // g\n",
    "    return signal.resample_poly(x, up, down).astype(float)\n",
    "\n",
    "\n",
    "def make_synthetic_clap(sr: int, duration: float = 0.14, decay: float = 3.8) -> np.ndarray:\n",
    "    n = int(sr * duration)\n",
    "    noise = np.random.randn(n)\n",
    "    env = np.exp(-np.linspace(0, decay, n))\n",
    "    clap = noise * env\n",
    "    clap[0] += 1.0  # impulso inicial claro\n",
    "    return normalize_audio(clap)\n",
    "\n",
    "\n",
    "def make_sine_sweep(sr: int, duration: float = 2.0, f0: float = 20.0, f1: float = 12_000.0) -> np.ndarray:\n",
    "    t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "    sweep = signal.chirp(t, f0=f0, f1=f1, t1=duration, method=\"logarithmic\")\n",
    "    window = signal.windows.tukey(len(sweep), alpha=0.1)\n",
    "    return normalize_audio(sweep * window)\n",
    "\n",
    "\n",
    "def load_mono_audio(path: Path, target_sr: int) -> np.ndarray:\n",
    "    audio, sr = sf.read(path, always_2d=False)\n",
    "    if audio.ndim > 1:\n",
    "        audio = audio.mean(axis=1)\n",
    "    return resample_audio(audio, sr, target_sr)\n",
    "\n",
    "\n",
    "def butter_filter(\n",
    "    x: np.ndarray,\n",
    "    sr: int,\n",
    "    mode: str,\n",
    "    f_low: float,\n",
    "    f_high: float,\n",
    "    order: int = 4,\n",
    ") -> np.ndarray:\n",
    "    mode = mode.lower()\n",
    "    if mode == \"none\":\n",
    "        return x\n",
    "    nyq = 0.5 * sr\n",
    "    f_low = max(10.0, min(f_low, nyq * 0.99))\n",
    "    f_high = max(f_low + 10.0, min(f_high, nyq * 0.999))\n",
    "\n",
    "    if mode == \"lowpass\":\n",
    "        wn = min(f_high / nyq, 0.999)\n",
    "        b, a = signal.butter(order, wn, btype=\"low\", output=\"ba\")\n",
    "    elif mode == \"highpass\":\n",
    "        wn = max(f_low / nyq, 1e-4)\n",
    "        b, a = signal.butter(order, wn, btype=\"high\", output=\"ba\")\n",
    "    elif mode == \"bandpass\":\n",
    "        lo = max(1e-4, min(f_low / nyq, 0.99))\n",
    "        hi = max(lo * 1.05, min(f_high / nyq, 0.999))\n",
    "        b, a = signal.butter(order, [lo, hi], btype=\"band\", output=\"ba\")\n",
    "    else:\n",
    "        return x\n",
    "    return signal.lfilter(b, a, x).astype(float)\n",
    "\n",
    "\n",
    "def apply_ir(x: np.ndarray, ir: np.ndarray, normalize: bool = True) -> np.ndarray:\n",
    "    y = signal.fftconvolve(x, ir, mode=\"full\")\n",
    "    return normalize_audio(y) if normalize else y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7689f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Respuestas al impulso\n",
    "# -----------------------------------------------------------------------------\n",
    "def _pad_to_length(x: np.ndarray, target: int) -> np.ndarray:\n",
    "    if len(x) >= target:\n",
    "        return x[:target]\n",
    "    out = np.zeros(target, dtype=float)\n",
    "    out[: len(x)] = x\n",
    "    return out\n",
    "\n",
    "\n",
    "def simulate_room_ir(\n",
    "    sr: int,\n",
    "    room_dim: tuple[float, float, float],\n",
    "    absorption: float,\n",
    "    max_order: int,\n",
    "    src_pos: tuple[float, float, float],\n",
    "    mic_pos: tuple[float, float, float],\n",
    "    ir_length_s: float,\n",
    ") -> np.ndarray:\n",
    "    materials = pra.Material(absorption)\n",
    "    room = pra.ShoeBox(room_dim, fs=sr, materials=materials, max_order=max_order)\n",
    "    room.add_source(src_pos)\n",
    "    mic_locs = np.array(mic_pos).reshape(3, 1)\n",
    "    room.add_microphone_array(pra.MicrophoneArray(mic_locs, room.fs))\n",
    "    room.compute_rir()\n",
    "    ir = np.asarray(room.rir[0][0], dtype=float)\n",
    "    target_len = int(sr * ir_length_s)\n",
    "    return normalize_audio(_pad_to_length(ir, target_len))\n",
    "\n",
    "\n",
    "def stepped_structure_ir(\n",
    "    sr: int,\n",
    "    step_height_m: float = 0.26,\n",
    "    step_depth_m: float = 0.30,\n",
    "    num_steps: int = 91,\n",
    "    listener_distance_m: float = 10.0,\n",
    "    step_reflection: float = 0.94,\n",
    "    distance_rolloff: float = 1.15,\n",
    "    jitter_ms: float = 0.06,\n",
    "    extra_decay_db_per_step: float = 0.0,\n",
    "    air_lowpass_hz: float | None = None,\n",
    "    ir_length_s: float = 0.45,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    IR sint√©tica basada en la escalinata de Kukulk√°n (eco del quetzal).\n",
    "    \"\"\"\n",
    "    c = 343.0  # velocidad del sonido [m/s]\n",
    "    steps = np.arange(num_steps, dtype=float)\n",
    "\n",
    "    z = steps * step_height_m\n",
    "    x = listener_distance_m + steps * step_depth_m\n",
    "    distances = np.sqrt(x**2 + z**2)\n",
    "    delays_s = 2.0 * distances / c\n",
    "\n",
    "    if jitter_ms > 0:\n",
    "        rng = np.random.default_rng(2024)\n",
    "        delays_s = np.maximum(delays_s + rng.normal(scale=jitter_ms / 1000.0, size=delays_s.shape), 0.0)\n",
    "\n",
    "    target_len = int(sr * ir_length_s)\n",
    "    max_delay = delays_s.max() if len(delays_s) else 0.0\n",
    "    total_len = max(target_len, int(math.ceil(max_delay * sr)) + 1)\n",
    "    ir = np.zeros(total_len, dtype=float)\n",
    "\n",
    "    tilt = 10 ** (-(extra_decay_db_per_step * steps) / 20.0)\n",
    "    amp = (step_reflection**steps) * tilt / (np.maximum(distances, 1e-3) ** distance_rolloff)\n",
    "    for a, d in zip(amp, delays_s):\n",
    "        idx = int(round(d * sr))\n",
    "        if idx < total_len:\n",
    "            ir[idx] += a\n",
    "\n",
    "    ir[0] += 0.02  # sonido directo suave\n",
    "    if air_lowpass_hz:\n",
    "        nyq = 0.5 * sr\n",
    "        cutoff = min(air_lowpass_hz, nyq * 0.95)\n",
    "        b, a = signal.butter(4, cutoff / nyq, btype=\"low\", output=\"ba\")\n",
    "        ir = signal.lfilter(b, a, ir)\n",
    "\n",
    "    return normalize_audio(_pad_to_length(ir, target_len))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=32)\n",
    "def get_ir(preset: str, sr: int) -> np.ndarray:\n",
    "    meta = IR_PRESETS[preset]\n",
    "    params = dict(meta[\"params\"])\n",
    "    if meta[\"type\"] == \"room\":\n",
    "        return simulate_room_ir(sr=sr, **params)\n",
    "    return stepped_structure_ir(sr=sr, **params)\n",
    "\n",
    "\n",
    "def estimate_rt60(ir: np.ndarray, sr: int) -> float:\n",
    "    energy = ir**2\n",
    "    energy_db = 10 * np.log10(energy / (np.max(energy) + 1e-12) + 1e-12)\n",
    "    try:\n",
    "        idx_5 = np.where(energy_db < -5)[0][0]\n",
    "        idx_35 = np.where(energy_db < -35)[0][0]\n",
    "        rt30 = (idx_35 - idx_5) / sr\n",
    "        return max(rt30 * 2, 0.0)\n",
    "    except IndexError:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2ca33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Gr√°ficos\n",
    "# -----------------------------------------------------------------------------\n",
    "def _figure_to_image(fig: plt.Figure) -> np.ndarray:\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return np.array(Image.open(buf))\n",
    "\n",
    "\n",
    "def waveform_image(x: np.ndarray, sr: int, color: str) -> np.ndarray:\n",
    "    t = np.arange(len(x)) / sr\n",
    "    fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.plot(t, x, lw=0.9, color=color)\n",
    "    ax.set_xlabel(\"Tiempo [s]\")\n",
    "    ax.set_ylabel(\"Amplitud\")\n",
    "    ax.set_title(\"Forma de onda ‚Äî salida\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    return _figure_to_image(fig)\n",
    "\n",
    "\n",
    "def spectrogram_image(x: np.ndarray, sr: int) -> np.ndarray:\n",
    "    f, t, Sxx = signal.spectrogram(x, fs=sr, nperseg=1024, noverlap=512, scaling=\"spectrum\")\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-12)\n",
    "    fig, ax = plt.subplots(figsize=(10, 3.5))\n",
    "    mesh = ax.pcolormesh(t, f, Sxx_db, shading=\"auto\", cmap=\"magma\")\n",
    "    ax.set_ylabel(\"Frecuencia [Hz]\")\n",
    "    ax.set_xlabel(\"Tiempo [s]\")\n",
    "    ax.set_ylim(0, min(sr / 2, 12_000))\n",
    "    ax.set_title(\"Espectrograma ‚Äî salida\")\n",
    "    fig.colorbar(mesh, ax=ax, label=\"Magnitud [dB]\")\n",
    "    fig.tight_layout()\n",
    "    return _figure_to_image(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b648e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Pipeline principal\n",
    "# -----------------------------------------------------------------------------\n",
    "def _slugify(text: str) -> str:\n",
    "    return \"\".join(ch if ch.isalnum() else \"_\" for ch in text.lower()).strip(\"_\")\n",
    "\n",
    "\n",
    "def prepare_download(y: np.ndarray, sr: int, label: str) -> str:\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    slug = _slugify(label or \"salida\")\n",
    "    path = OUTPUTS_DIR / f\"auralizacion_{slug}_{timestamp}.wav\"\n",
    "    sf.write(path, y, sr)\n",
    "    return str(path)\n",
    "\n",
    "\n",
    "def describe_session(\n",
    "    signal_label: str,\n",
    "    ir_label: str,\n",
    "    sr: int,\n",
    "    y: np.ndarray,\n",
    "    ir: np.ndarray,\n",
    "    filter_label: str,\n",
    ") -> str:\n",
    "    duration = len(y) / sr\n",
    "    peak = np.max(np.abs(y))\n",
    "    rms = np.sqrt(np.mean(y**2))\n",
    "    rt60 = estimate_rt60(ir, sr)\n",
    "    return (\n",
    "        f\"**Entrada:** {signal_label} ‚Äî {sr:,} Hz\\n\"\n",
    "        f\"**IR:** {ir_label} ¬∑ RT60 ‚âà {rt60:.2f} s\\n\"\n",
    "        f\"**Filtro posterior:** {filter_label}\\n\"\n",
    "        f\"**Salida:** {duration:.2f} s ¬∑ Pico {peak:.2f} ¬∑ RMS {rms:.3f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_input_signal(\n",
    "    source: str,\n",
    "    upload: tuple[int, np.ndarray] | None,\n",
    "    sr: int,\n",
    "    clap_duration: float,\n",
    "    sweep_duration: float,\n",
    ") -> tuple[np.ndarray, str]:\n",
    "    if source.startswith(\"Aplauso\"):\n",
    "        return make_synthetic_clap(sr, duration=clap_duration), \"Aplauso sint√©tico\"\n",
    "    if source.startswith(\"Barrido\"):\n",
    "        return make_sine_sweep(sr, duration=sweep_duration), \"Barrido senoidal log\"\n",
    "\n",
    "    if not upload:\n",
    "        raise gr.Error(\"Debes subir un archivo de audio para esta opci√≥n.\")\n",
    "    up_sr, samples = upload\n",
    "    samples = np.asarray(samples, dtype=float)\n",
    "    if samples.ndim > 1:\n",
    "        samples = samples.mean(axis=1)\n",
    "    resampled = resample_audio(samples, int(up_sr), sr)\n",
    "    if not np.any(resampled):\n",
    "        raise gr.Error(\"El archivo de audio parece estar vac√≠o.\")\n",
    "    return normalize_audio(resampled), \"Audio subido\"\n",
    "\n",
    "\n",
    "def process(\n",
    "    sample_rate: int,\n",
    "    signal_source: str,\n",
    "    clap_duration: float,\n",
    "    sweep_duration: float,\n",
    "    uploaded_audio: tuple[int, np.ndarray] | None,\n",
    "    ir_source_type: str,\n",
    "    ir_choice: str,\n",
    "    uploaded_ir: tuple[int, np.ndarray] | None,\n",
    "    normalize_output: bool,\n",
    "    filter_choice: str,\n",
    "    freq_low: float,\n",
    "    freq_high: float,\n",
    ") -> tuple[\n",
    "    tuple[int, np.ndarray],\n",
    "    tuple[int, np.ndarray],\n",
    "    tuple[int, np.ndarray],\n",
    "    np.ndarray,\n",
    "    np.ndarray,\n",
    "    str,\n",
    "    str,\n",
    "]:\n",
    "    sr = int(sample_rate)\n",
    "    x, signal_label = get_input_signal(signal_source, uploaded_audio, sr, clap_duration, sweep_duration)\n",
    "\n",
    "    # Selecci√≥n de IR\n",
    "    if ir_source_type == \"Preset\":\n",
    "        ir = get_ir(ir_choice, sr)\n",
    "        ir_label = ir_choice\n",
    "        meta = IR_PRESETS[ir_choice]\n",
    "        color = meta[\"color\"]\n",
    "    else:\n",
    "        # IR subida por el usuario\n",
    "        if not uploaded_ir:\n",
    "            raise gr.Error(\"Por favor, sube un archivo de IR o selecciona 'Preset'.\")\n",
    "        up_sr, samples = uploaded_ir\n",
    "        samples = np.asarray(samples, dtype=float)\n",
    "        if samples.ndim > 1:\n",
    "            samples = samples.mean(axis=1)\n",
    "        \n",
    "        # Resamplear si es necesario\n",
    "        ir = resample_audio(samples, int(up_sr), sr)\n",
    "        # Normalizar para evitar problemas de ganancia excesiva\n",
    "        ir = normalize_audio(ir)\n",
    "        \n",
    "        ir_label = \"IR Personalizada\"\n",
    "        color = \"#444444\"  # Color gris oscuro para IRs custom\n",
    "\n",
    "    y = apply_ir(x, ir, normalize=normalize_output)\n",
    "\n",
    "    filter_mode = FILTER_MAP.get(filter_choice, \"none\")\n",
    "    if filter_mode != \"none\":\n",
    "        y = butter_filter(y, sr, filter_mode, freq_low, freq_high)\n",
    "        if normalize_output:\n",
    "            y = normalize_audio(y)\n",
    "\n",
    "    # Usamos 'color' determinado arriba\n",
    "    wave_img = waveform_image(y, sr, color)\n",
    "    spec_img = spectrogram_image(y, sr)\n",
    "    summary = describe_session(signal_label, ir_label, sr, y, ir, filter_choice)\n",
    "    download_path = prepare_download(y, sr, f\"{signal_label}_{_slugify(ir_label)}\")\n",
    "\n",
    "    return (\n",
    "        (sr, x),\n",
    "        (sr, ir),\n",
    "        (sr, y),\n",
    "        wave_img,\n",
    "        spec_img,\n",
    "        summary,\n",
    "        download_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108e3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Interfaz Gradio\n",
    "# -----------------------------------------------------------------------------\n",
    "DESCRIPTION_MD = \"\"\"\n",
    "# Hito 3 ¬∑ Prototipo de Convoluci√≥n Avanzado\n",
    "\n",
    "Explora el fen√≥meno del ‚Äúeco del quetzal‚Äù y presets de salas, o **sube tus propias Respuestas al Impulso (IR)**.\n",
    "Configura la se√±al de entrada (duraci√≥n del aplauso o barrido), selecciona la IR y aplica filtros sencillos.\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(title=\"Hito 3 ‚Äî Demo de Convoluci√≥n\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(DESCRIPTION_MD)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            sample_rate = gr.Dropdown(\n",
    "                label=\"Frecuencia de muestreo\",\n",
    "                choices=SAMPLE_RATE_OPTIONS,\n",
    "                value=SAMPLE_RATE_OPTIONS[0],\n",
    "            )\n",
    "            signal_source = gr.Dropdown(label=\"Se√±al de entrada\", choices=INPUT_OPTIONS, value=INPUT_OPTIONS[0])\n",
    "            clap_duration = gr.Slider(\n",
    "                minimum=0.05,\n",
    "                maximum=0.50,\n",
    "                value=0.14,\n",
    "                step=0.01,\n",
    "                label=\"Duraci√≥n aplauso sint√©tico [s]\",\n",
    "            )\n",
    "            sweep_duration = gr.Slider(\n",
    "                minimum=0.5,\n",
    "                maximum=5.0,\n",
    "                value=2.0,\n",
    "                step=0.1,\n",
    "                label=\"Duraci√≥n barrido senoidal [s]\",\n",
    "            )\n",
    "            uploaded_audio = gr.Audio(\n",
    "                label=\"Audio personalizado (usa esta entrada cuando selecciones 'Subir un audio')\",\n",
    "                type=\"numpy\",\n",
    "            )\n",
    "\n",
    "            # --- Selecci√≥n de IR ---\n",
    "            ir_source_type = gr.Radio(\n",
    "                label=\"Fuente de Respuesta al Impulso\",\n",
    "                choices=[\"Preset\", \"Subir archivo\"],\n",
    "                value=\"Preset\"\n",
    "            )\n",
    "            \n",
    "            with gr.Column(visible=True) as preset_col:\n",
    "                ir_choice = gr.Dropdown(label=\"Seleccionar Preset\", choices=list(IR_PRESETS.keys()), value=\"Sala mediana\")\n",
    "            \n",
    "            with gr.Column(visible=False) as upload_col:\n",
    "                uploaded_ir = gr.Audio(label=\"Subir archivo de IR\", type=\"numpy\")\n",
    "\n",
    "            def toggle_ir_source(source):\n",
    "                return {\n",
    "                    preset_col: gr.update(visible=(source == \"Preset\")),\n",
    "                    upload_col: gr.update(visible=(source == \"Subir archivo\"))\n",
    "                }\n",
    "\n",
    "            ir_source_type.change(fn=toggle_ir_source, inputs=ir_source_type, outputs=[preset_col, upload_col])\n",
    "            # -----------------------\n",
    "\n",
    "            normalize_output = gr.Checkbox(label=\"Normalizar salida\", value=True)\n",
    "\n",
    "            filter_choice = gr.Dropdown(label=\"Filtro posterior\", choices=list(FILTER_MAP.keys()), value=\"Ninguno\")\n",
    "            freq_low = gr.Slider(minimum=20.0, maximum=5_000.0, value=200.0, step=10.0, label=\"Frecuencia baja [Hz]\")\n",
    "            freq_high = gr.Slider(minimum=200.0, maximum=18_000.0, value=3_000.0, step=10.0, label=\"Frecuencia alta [Hz]\")\n",
    "\n",
    "            process_btn = gr.Button(\"Procesar\", variant=\"primary\")\n",
    "\n",
    "        with gr.Column():\n",
    "            input_audio = gr.Audio(label=\"Se√±al de entrada\", type=\"numpy\")\n",
    "            ir_audio = gr.Audio(label=\"Respuesta al impulso\", type=\"numpy\")\n",
    "            output_audio = gr.Audio(label=\"Auralizaci√≥n (salida)\", type=\"numpy\")\n",
    "            waveform_output = gr.Image(label=\"Forma de onda\", height=275)\n",
    "            spectrogram_output = gr.Image(label=\"Espectrograma\", height=320)\n",
    "            summary_output = gr.Markdown(label=\"Resumen\")\n",
    "            download_output = gr.File(label=\"Descargar WAV\")\n",
    "\n",
    "    examples = gr.Examples(\n",
    "        label=\"Ejemplos r√°pidos\",\n",
    "        examples=[\n",
    "            [48_000, \"Aplauso sint√©tico\", 0.14, 2.0, None, \"Preset\", \"Pir√°mide (Quetzal) üå™Ô∏è\", None, True, \"Ninguno\", 200.0, 3_000.0],\n",
    "            [44_100, \"Barrido senoidal (20 Hz ‚Äì 12 kHz)\", 0.14, 2.8, None, \"Preset\", \"Sala grande / Hall\", None, True, \"Pasa-bajos\", 20.0, 2_000.0],\n",
    "        ],\n",
    "        inputs=[\n",
    "            sample_rate,\n",
    "            signal_source,\n",
    "            clap_duration,\n",
    "            sweep_duration,\n",
    "            uploaded_audio,\n",
    "            ir_source_type,\n",
    "            ir_choice,\n",
    "            uploaded_ir,\n",
    "            normalize_output,\n",
    "            filter_choice,\n",
    "            freq_low,\n",
    "            freq_high,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    process_btn.click(\n",
    "        fn=process,\n",
    "        inputs=[\n",
    "            sample_rate,\n",
    "            signal_source,\n",
    "            clap_duration,\n",
    "            sweep_duration,\n",
    "            uploaded_audio,\n",
    "            ir_source_type,\n",
    "            ir_choice,\n",
    "            uploaded_ir,\n",
    "            normalize_output,\n",
    "            filter_choice,\n",
    "            freq_low,\n",
    "            freq_high,\n",
    "        ],\n",
    "        outputs=[\n",
    "            input_audio,\n",
    "            ir_audio,\n",
    "            output_audio,\n",
    "            waveform_output,\n",
    "            spectrogram_output,\n",
    "            summary_output,\n",
    "            download_output,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Lanzar la demo\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acustica",
   "language": "python",
   "name": "acustica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
