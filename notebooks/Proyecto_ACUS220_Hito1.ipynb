{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047d525e",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"../data/uach.png\" alt=\"UACh\" width=\"200\"/>\n",
    "    </p>\n",
    "\n",
    "# Proyecto de ACUS 220 Acústica Computacional con Python  \n",
    "\n",
    "## Convolución y Modelado 3D\n",
    "\n",
    "### Primer Hito de Entrega  \n",
    "\n",
    "**Integrantes:** Carlos Duarte, Fernando Castillo, Vicente Alves, Antonio Duque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce9095",
   "metadata": {},
   "source": [
    "## Objetivos del Proyecto  \n",
    "\n",
    "**Objetivo General:**  \n",
    "- Este proyecto busca replicar fenómenos acústicos como el de la Pirámide de Chichén Itzá, donde un aplauso se transforma en el canto de un pájaro debido a la geometría y materiales de la estructura. [1] \n",
    "\n",
    "**Objetivos Específicos:**  \n",
    "- OE1: Implementar en Python el procesamiento por convolución.  \n",
    "- OE2: Validar el modelo comparando espectrogramas y señales auralizadas con las grabaciones reales/medidas y discutir las limitaciones físicas (materiales, difracción, dependencia del espectro del impulso). [2]  \n",
    "- OE3: Diseñar y simular estructuras geométricas 3D utilizando pyroomacoustics que permitan replicar o aproximar transformaciones acústicas específicas, experimentando con diferentes configuraciones de materiales y geometrías para demostrar cómo el diseño espacial modifica las características del sonido. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba83cb",
   "metadata": {},
   "source": [
    "## Estado del Arte  \n",
    "\n",
    "En esta sección, el grupo debe presentar un resumen de lo que se ha encontrado en la literatura, plataformas o proyectos relacionados con el problema que quieren resolver.  \n",
    "\n",
    "**Ejemplo:**  \n",
    "- Fenómeno observado: Un aplauso frente a la pirámide de Chichén Itzá produce un eco con caŕacter \"tonal\" que ha sido documentado por investigadores y prensa especializado. Estudios indican que la forma del eco esta fuertemente ligada a la interacción onda-escalón(difracción + reflexiones) y depende del contenido espectral del aplauso.\n",
    "\n",
    "- Pyroomacoustics y simulación de salas/acústica\n",
    "Scheibler, Bezzam y Dokmanić (2017) presentan el paquete Pyroomacoustics, diseñado para facilitar el desarrollo y prueba de algoritmos de procesamiento de audio en entornos acústicos. [3]\n",
    "  - El paquete ofrece una interfaz orientada a objetos para construir escenarios con múltiples fuentes y micrófonos en habitaciones 2D y 3D.\n",
    "  - Incluye una implementación eficiente en C del modelo de fuentes por imagen (“image source model”) para generar respuestas al impulso (IR) en habitaciones poliédricas generales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc17aa5",
   "metadata": {},
   "source": [
    "## Materiales y Métodos  \n",
    "\n",
    "### Materiales  \n",
    "- Grabador de audio.\n",
    "- PC con Python (recomendado: Python 3.10+)\n",
    "- librerías: \n",
    "  - numpy\n",
    "  - scipy\n",
    "  - matplotlib\n",
    "  - librosa\n",
    "  - pyroomacoustics\n",
    "  - soundfile\n",
    "\n",
    "### Metodología  \n",
    "La metodología propuesta para el desarrollo del proyecto se estructura en **siete etapas principales**, que permiten avanzar de la teoría al análisis experimental y computacional.  \n",
    "\n",
    "#### 1. Revisión del estado del arte\n",
    "- Investigar antecedentes sobre:\n",
    "  - Respuesta al impulso (IR) y auralización.\n",
    "  - Procesamiento por convolución en acústica.\n",
    "\n",
    "#### 2. Definición del problema y objetivos\n",
    "- Objetivo general: *Reproducir y analizar el efecto chirp mediante procesamiento por convolución en Python*.  \n",
    "- Subobjetivos:\n",
    "  - Obtener o generar una IR representativa.\n",
    "  - Implementar la convolución digital.\n",
    "  - Analizar los resultados en el dominio tiempo–frecuencia.\n",
    "  - Comparar con referencias experimentales o teóricas.\n",
    "\n",
    "#### 3. Obtención de la Respuesta al Impulso (IR)\n",
    "- Simulación numérica: uso de librerías como `pyroomacoustics`. \n",
    "\n",
    "#### 4. Procesamiento por convolución\n",
    "- Implementar la convolución en Python\n",
    "- Señal de entrada: un aplauso o sonido de prueba.  \n",
    "- Filtro: la IR obtenida o generada.  \n",
    "- Normalización de la señal resultante.  \n",
    "- Exportar el audio en formato `.wav`.\n",
    "\n",
    "#### 5. Análisis del resultado\n",
    " \n",
    "#### 6. Validación\n",
    "- Comparación perceptiva y espectral con registros reales.  \n",
    "- Evaluación de la similitud mediante métricas objetivas (correlación espectral, RMS error).\n",
    "\n",
    "#### 7. Discusión y conclusiones\n",
    "- Relacionar resultados obtenidos con la teoría acústica.  \n",
    "- Identificar limitaciones del método (modelos, ruido, simplificaciones).  \n",
    "- Proponer mejoras y trabajos futuros.\n",
    "\n",
    "### Planificación\n",
    "| Actividad | Responsable(s) | Fecha estimada de término |\n",
    "| :--- | :--- | :--- |\n",
    "| 1. Revisión bibliográfica sobre IR, auralización y convolución digital | Grupo completo | 02/10/2025 |\n",
    "| 2. Definición de Objetivos y Recolección de Datos | Grupo completo | 02/10/2025 |\n",
    "| 3. Implementación de Convolución en Python | | 10/10/2025 |\n",
    "| 4. Codificación inicial, manejo de librerías (pyroomacoustics, etc.) | | 17/10/2025 |\n",
    "| 5. Normalización | | 24/10/2025 |\n",
    "| 6. Generación de Señales Auralizadas y Análisis Inicial | | 31/10/2025 |\n",
    "| 7. Procesar el audio de prueba (aplauso), exportar .wav y análisis básico tiempo-frecuencia | | 07/11/2025 |\n",
    "| 8. Validación del Modelo - Comparación espectral, cálculo de métricas objetivas | | 14/11/2025 |\n",
    "| 9. Redacción del Informe Parcial/Final - Discusión de resultados, limitaciones e identificación de mejoras. | Grupo completo | 21/11/2025 |\n",
    "| 10. Revisión, Ajustes Finales y Entrega | Grupo completo | 28/11/2025 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb4b2e",
   "metadata": {},
   "source": [
    "## Referencias Bibliográficas  \n",
    "\n",
  
    "\n",
    "[1] Declercq, N. F., Degrieck, J., Briers, R., & Leroy, O. (2004). A theoretical study of special acoustic effects caused by the staircase of the El Castillo pyramid at the Maya ruins of Chichen-Itza in Mexico. The Journal of the Acoustical Society of America, 116(6), 3328–3335. https://doi.org/10.1121/1.1764833\n",
    "\n",
    "‌[2] Declercq, N. F., Degrieck, J., Briers, R., & Leroy, O. (2003). A full simulation of the Quetzal echo at the Mayan pyramid of Kukulkan at Chichen Itza in Mexico. The Journal of the Acoustical Society of America, 113(4), 2189–2189. https://doi.org/10.1121/1.4780130\n",
    "\n",
    "[3] Scheibler, R., Bezzam, E., & Dokmanić, I. (2018, abril). Pyroomacoustics: A Python package for audio room simulation and array processing algorithms. En 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 351–355). IEEE. https://doi.org/10.1109/ICASSP.2018.8461310\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976b888-1626-4d5a-bda1-70e82a47c291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acustica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
