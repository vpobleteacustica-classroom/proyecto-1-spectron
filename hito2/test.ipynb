{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5351c3a2",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../data/uach.png\" alt=\"UACh\" width=\"180\">\n",
    "</p>\n",
    "\n",
    "# Hito 2 â€” Prototipo de ConvoluciÃ³n\n",
    "\n",
    "Proyecto ACUS220 Â· AcÃºstica Computacional con Python\n",
    "\n",
    "Este notebook implementa un prototipo funcional para auralizaciÃ³n por convoluciÃ³n con una librerÃ­a de presets de respuestas al impulso (IR). Permite generar una seÃ±al de entrada (o cargar una), seleccionar una IR (salas y un modelo escalonado tipo â€˜Quetzalâ€™), aplicar filtros simples y escuchar/visualizar el resultado, ademÃ¡s de exportar a WAV.\n",
    "\n",
    "**Integrantes:** Carlos Duarte, Fernando Castillo, Vicente Alves, Antonio Duque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb1ed4",
   "metadata": {},
   "source": [
    "## 1. IntroducciÃ³n\n",
    "\n",
    "### 1.1 Problema\n",
    "\n",
    "### 1.2 Herramienta de convoluciÃ³n\n",
    "\n",
    "$ y(t) = x(t) * h(t) $\n",
    "\n",
    "### 1.3 Objetivos de este anÃ¡lisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4132c",
   "metadata": {},
   "source": [
    "## 2. AnÃ¡lisis preliminar\n",
    "\n",
    "### 2.1 GeneraciÃ³n de seÃ±ales de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcf3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar por ejemplo un audio de un aplauso, graficar su forma de onda y espectrograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1ea5b",
   "metadata": {},
   "source": [
    "### 2.2 CaracterÃ­sticas de la seÃ±al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analisis: duraciÃ³n, frecuencia, espectro de magnitud, etc......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73158a",
   "metadata": {},
   "source": [
    "## 3. Respuesta al impulso (IR)\n",
    "\n",
    "### 3.1 Â¿QuÃ© es IR?\n",
    "\n",
    "### 3.2 Â¿QuÃ© es la convoluciÃ³n?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e4b4f",
   "metadata": {},
   "source": [
    "## QuÃ© hace este prototipo\n",
    "- Entradas: aplauso sintÃ©tico, barrido senoidal o cargar WAV.\n",
    "- Presets de IR: salas (pequeÃ±a/mediana/gran sala) y un modelo escalonado â€˜PirÃ¡mide (Quetzal)â€™.\n",
    "- Procesamiento: convoluciÃ³n FFT + normalizaciÃ³n opcional + filtro simple (lowpass/highpass/bandpass).\n",
    "- Salida: reproductor de audio, forma de onda, espectrograma y opciÃ³n de exportar WAV a `hito2/data/outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno listo.\n"
     ]
    }
   ],
   "source": [
    "import os, time, math, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import pyroomacoustics as pra\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "DATA_DIR = Path('data')\n",
    "IN_DIR = DATA_DIR / 'inputs'\n",
    "OUT_DIR = DATA_DIR / 'outputs'\n",
    "IN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Entorno listo.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbec1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilidades de audio y visualizaciÃ³n\n",
    "def normalize_audio(x, peak=0.98):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.max(np.abs(x)) + 1e-12\n",
    "    return (x / m) * peak\n",
    "\n",
    "def resample_if_needed(x, sr, target_sr):\n",
    "    if target_sr is None or sr == target_sr:\n",
    "        return x, sr\n",
    "    g = math.gcd(int(sr), int(target_sr))\n",
    "    up = target_sr // g\n",
    "    down = sr // g\n",
    "    xr = signal.resample_poly(x, up, down)\n",
    "    return xr.astype(float), target_sr\n",
    "\n",
    "def load_audio(path, target_sr=None, mono=True):\n",
    "    x, sr = sf.read(path, always_2d=False)\n",
    "    if x.ndim > 1 and mono:\n",
    "        x = x.mean(axis=1)\n",
    "    x, sr = resample_if_needed(x, sr, target_sr)\n",
    "    return x.astype(float), sr\n",
    "\n",
    "def save_audio(path, x, sr):\n",
    "    sf.write(str(path), x, int(sr))\n",
    "\n",
    "def plot_waveform(x, sr, title='SeÃ±al'):\n",
    "    t = np.arange(len(x)) / sr\n",
    "    plt.figure()\n",
    "    plt.plot(t, x, lw=0.9)\n",
    "    plt.xlabel('Tiempo [s]')\n",
    "    plt.ylabel('Amplitud')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrogram(x, sr, title='Espectrograma'):\n",
    "    f, t, Sxx = signal.spectrogram(x, fs=sr, nperseg=1024, noverlap=512, scaling='spectrum')\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-12)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(t, f, Sxx_db, shading='auto', cmap='magma')\n",
    "    plt.ylabel('Frecuencia [Hz]')\n",
    "    plt.xlabel('Tiempo [s]')\n",
    "    plt.ylim(0, sr/2)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label='dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def play(x, sr):\n",
    "    display(Audio(x, rate=sr))\n",
    "\n",
    "def make_synthetic_clap(sr=48000, duration_s=0.12, decay=3.5, noise_level=0.3):\n",
    "    n = int(sr * duration_s)\n",
    "    x = np.zeros(n)\n",
    "    x[0] = 1.0  # impulso inicial\n",
    "    rn = np.random.randn(n)\n",
    "    env = np.exp(-np.linspace(0, decay, n))\n",
    "    x += noise_level * rn * env\n",
    "    return normalize_audio(x)\n",
    "\n",
    "def make_sine_sweep(sr=48000, dur_s=2.0, f0=20.0, f1=12000.0):\n",
    "    t = np.linspace(0, dur_s, int(sr*dur_s), endpoint=False)\n",
    "    x = signal.chirp(t, f0=f0, f1=f1, t1=dur_s, method='logarithmic')\n",
    "    win = signal.windows.tukey(len(x), alpha=0.1)\n",
    "    return normalize_audio(x*win)\n",
    "\n",
    "def butter_filter(x, sr, ftype='none', f_lo=200.0, f_hi=3000.0, order=4):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    nyq = 0.5 * sr\n",
    "    f_lo = max(10.0, min(f_lo, nyq*0.99))\n",
    "    f_hi = max(20.0, min(f_hi, nyq*0.99))\n",
    "    if ftype == 'none':\n",
    "        return x\n",
    "    if ftype == 'lowpass':\n",
    "        wn = min(f_hi/nyq, 0.999)\n",
    "        b, a = signal.butter(order, wn, btype='low', output='ba')\n",
    "    elif ftype == 'highpass':\n",
    "        wn = max(f_lo/nyq, 1e-4)\n",
    "        b, a = signal.butter(order, wn, btype='high', output='ba')\n",
    "    elif ftype == 'bandpass':\n",
    "        lo = max(1e-4, min(f_lo/nyq, 0.99))\n",
    "        hi = max(lo*1.01, min(f_hi/nyq, 0.999))\n",
    "        b, a = signal.butter(order, [lo, hi], btype='band', output='ba')\n",
    "    else:\n",
    "        return x\n",
    "    return signal.lfilter(b, a, x)\n",
    "\n",
    "def apply_ir(x, ir, normalize=True):\n",
    "    y = signal.fftconvolve(x, ir, mode='full')\n",
    "    return normalize_audio(y) if normalize else y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeneraciÃ³n de IRs: sala (Pyroomacoustics) y estructura escalonada (â€˜Quetzalâ€™)\n",
    "def pad_to_length(x, n):\n",
    "    if len(x) >= n:\n",
    "        return x[:n]\n",
    "    out = np.zeros(n)\n",
    "    out[:len(x)] = x\n",
    "    return out\n",
    "\n",
    "def simulate_room_ir(\n",
    "    sr=48000,\n",
    "    room_dim=(8.0, 5.0, 3.0),\n",
    "    absorption=0.2,\n",
    "    max_order=10,\n",
    "    src_pos=(2.0, 2.0, 1.5),\n",
    "    mic_pos=(6.0, 3.0, 1.5),\n",
    "    ir_length_s=1.2,\n",
    "):\n",
    "    materials = pra.Material(absorption)\n",
    "    room = pra.ShoeBox(room_dim, fs=sr, materials=materials, max_order=max_order)\n",
    "    room.add_source(src_pos)\n",
    "    mic_locs = np.array(mic_pos).reshape(-1, 1)\n",
    "    room.add_microphone_array(pra.MicrophoneArray(mic_locs, room.fs))\n",
    "    room.compute_rir()\n",
    "    ir = np.asarray(room.rir[0][0], dtype=float)\n",
    "    N = int(sr * ir_length_s)\n",
    "    ir = pad_to_length(ir, N)\n",
    "    return normalize_audio(ir)\n",
    "\n",
    "def stepped_structure_ir(\n",
    "    sr=48000,\n",
    "    base_delay_ms=6.0,   # primer retardo\n",
    "    step_delta_ms=1.2,   # incremento de retardo por eco\n",
    "    accel_ms=-0.03,      # curvatura temporal (chirp en tiempos)\n",
    "    num_steps=45,        # cantidad de ecos\n",
    "    decay=0.92,          # atenuaciÃ³n por paso\n",
    "    ir_length_s=1.4,\n",
    "):\n",
    "    delays_ms = []\n",
    "    for n in range(num_steps):\n",
    "        t = base_delay_ms + n * step_delta_ms + 0.5 * accel_ms * n * (n - 1)\n",
    "        if t >= 0:\n",
    "            delays_ms.append(t)\n",
    "    if not delays_ms:\n",
    "        return np.array([1.0])\n",
    "    max_delay_ms = max(delays_ms)\n",
    "    N = int(sr * ir_length_s)\n",
    "    L = max(N, int(sr * (max_delay_ms / 1000.0)) + sr // 10)\n",
    "    ir = np.zeros(L)\n",
    "    for i, t_ms in enumerate(delays_ms):\n",
    "        idx = int(round(sr * (t_ms / 1000.0)))\n",
    "        if idx < L:\n",
    "            ir[idx] += decay ** i\n",
    "    ir[0] += 0.05\n",
    "    ir = ir[:N] if N < len(ir) else ir\n",
    "    return normalize_audio(ir)\n",
    "\n",
    "def get_preset_ir(preset, sr):\n",
    "    preset = str(preset).lower().strip()\n",
    "    if preset.startswith('sala pequeÃ±a'):\n",
    "        ir = simulate_room_ir(sr=sr, room_dim=(4.0, 3.0, 2.5), absorption=0.45, max_order=8,\n",
    "                            src_pos=(1.2,1.0,1.2), mic_pos=(3.2,1.8,1.2), ir_length_s=1.0)\n",
    "        label = 'Sala pequeÃ±a'\n",
    "    elif preset.startswith('sala mediana'):\n",
    "        ir = simulate_room_ir(sr=sr, room_dim=(8.0, 5.5, 3.2), absorption=0.25, max_order=12,\n",
    "                            src_pos=(2.0,2.3,1.5), mic_pos=(6.0,3.1,1.5), ir_length_s=1.2)\n",
    "        label = 'Sala mediana'\n",
    "    elif 'hall' in preset or 'grande' in preset:\n",
    "        ir = simulate_room_ir(sr=sr, room_dim=(16.0, 11.0, 6.0), absorption=0.12, max_order=15,\n",
    "                            src_pos=(4.0,3.0,2.0), mic_pos=(12.0,7.0,2.5), ir_length_s=1.6)\n",
    "        label = 'Sala grande / Hall'\n",
    "    else:\n",
    "        ir = stepped_structure_ir(sr=sr)\n",
    "        label = 'PirÃ¡mide (Quetzal)'\n",
    "    return ir, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28955c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9b1f0070d74049905dd3d81cf5b141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Frecuencia de muestreo', options=(48000, 44100), value=480â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interfaz interactiva con ipywidgets\n",
    "# Controles\n",
    "sr_dd = widgets.Dropdown(options=[48000, 44100], value=48000, description='Frecuencia de muestreo')\n",
    "in_src = widgets.Dropdown(\n",
    "    options=['Aplauso (sintÃ©tico)', 'Barrido senoidal (20 Hzâ€“12 kHz)', 'Cargar WAV (carpeta inputs)'],\n",
    "    value='Aplauso (sintÃ©tico)', description='Entrada'\n",
    ")\n",
    "wav_path = widgets.Text(value=str(IN_DIR / 'mi_audio.wav'), description='Ruta WAV', layout=widgets.Layout(width='50%'))\n",
    "\n",
    "preset_dd = widgets.Dropdown(\n",
    "    options=['Sala pequeÃ±a', 'Sala mediana', 'Sala grande / Hall', 'PirÃ¡mide (Quetzal) ðŸŒªï¸'],\n",
    "    value='Sala mediana', description='Preajuste de IR'\n",
    ")\n",
    "\n",
    "# Filtro de coloraciÃ³n (post-EQ)\n",
    "eq_dd = widgets.Dropdown(options=['Ninguno', 'Pasa-bajos', 'Pasa-altos', 'Pasa-banda'], value='Ninguno', description='Filtro (posterior)')\n",
    "f_lo = widgets.FloatSlider(value=200.0, min=20.0, max=5000.0, step=10.0, description='Frecuencia baja [Hz]')\n",
    "f_hi = widgets.FloatSlider(value=3000.0, min=200.0, max=18000.0, step=10.0, description='Frecuencia alta [Hz]')\n",
    "normalize_ck = widgets.Checkbox(value=True, description='Normalizar')\n",
    "\n",
    "render_btn = widgets.Button(description='Procesar', button_style='primary')\n",
    "save_btn = widgets.Button(description='Exportar WAV', button_style='')\n",
    "out = widgets.Output()\n",
    "\n",
    "state = {'y': None, 'sr': None, 'label': None, 'busy': False}\n",
    "\n",
    "def _slug(s):\n",
    "    return ''.join(ch for ch in s.lower() if ch.isalnum() or ch in ('-', '_')).replace(' ', '_')\n",
    "\n",
    "def do_render(_=None):\n",
    "    if state.get('busy'):\n",
    "        return\n",
    "    state['busy'] = True\n",
    "    render_btn.disabled = True\n",
    "    try:\n",
    "        sr = int(sr_dd.value)\n",
    "        # Entrada\n",
    "        if in_src.value.startswith('Aplauso'):\n",
    "            x = make_synthetic_clap(sr=sr)\n",
    "        elif in_src.value.startswith('Barrido senoidal'):\n",
    "            x = make_sine_sweep(sr=sr)\n",
    "        else:\n",
    "            x, _sr = load_audio(wav_path.value, target_sr=sr)\n",
    "        # IR\n",
    "        ir, label = get_preset_ir(preset_dd.value, sr)\n",
    "        # ConvoluciÃ³n\n",
    "        y = apply_ir(x, ir, normalize=normalize_ck.value)\n",
    "        # Post-EQ\n",
    "        eq_mode = eq_dd.value.lower()\n",
    "        if eq_mode != 'ninguno':\n",
    "            mode_map = {'pasa-bajos': 'lowpass', 'pasa-altos': 'highpass', 'pasa-banda': 'bandpass'}\n",
    "            y = butter_filter(y, sr, ftype=mode_map.get(eq_mode, 'none'), f_lo=f_lo.value, f_hi=f_hi.value, order=4)\n",
    "            if normalize_ck.value:\n",
    "                y = normalize_audio(y)\n",
    "        # Estado para exportar\n",
    "        state['y'] = y\n",
    "        state['sr'] = sr\n",
    "        state['label'] = label\n",
    "        # Mostrar\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            print(f'Entrada: {in_src.value} | IR: {label} | Frecuencia de muestreo: {sr} Hz')\n",
    "            print('â€” SeÃ±al de entrada')\n",
    "            play(x, sr)\n",
    "            print('â€” Respuesta al impulso (escuchar a bajo volumen)')\n",
    "            play(ir, sr)\n",
    "            print('â€” SeÃ±al de salida (convoluciÃ³n)')\n",
    "            play(y, sr)\n",
    "            plot_waveform(y, sr, title='Salida â€” forma de onda')\n",
    "            plot_spectrogram(y, sr, title='Salida â€” espectrograma')\n",
    "    finally:\n",
    "        state['busy'] = False\n",
    "        render_btn.disabled = False\n",
    "\n",
    "def do_save(_=None):\n",
    "    y = state.get('y'); sr = state.get('sr'); label = state.get('label') or 'out'\n",
    "    if y is None or sr is None:\n",
    "        with out: print('No hay resultado para exportar. Pulsa Procesar primero.')\n",
    "        return\n",
    "    fname = f'out_{_slug(label)}_{int(time.time())}.wav'\n",
    "    fpath = OUT_DIR / fname\n",
    "    save_audio(fpath, y, sr)\n",
    "    with out: print('Exportado:', fpath)\n",
    "\n",
    "# Evitar callbacks duplicados si se re-ejecuta la celda\n",
    "try:\n",
    "    render_btn._click_handlers.callbacks.clear()\n",
    "    save_btn._click_handlers.callbacks.clear()\n",
    "except Exception:\n",
    "    pass\n",
    "render_btn.on_click(do_render)\n",
    "save_btn.on_click(do_save)\n",
    "\n",
    "ui_top = widgets.HBox([sr_dd, in_src])\n",
    "ui_path = widgets.HBox([wav_path])\n",
    "ui_preset = widgets.HBox([preset_dd])\n",
    "ui_eq = widgets.HBox([eq_dd, f_lo, f_hi, normalize_ck])\n",
    "ui_btns = widgets.HBox([render_btn, save_btn])\n",
    "ui = widgets.VBox([ui_top, ui_path, ui_preset, ui_eq, ui_btns, out])\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
