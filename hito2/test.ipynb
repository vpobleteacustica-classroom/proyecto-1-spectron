{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5351c3a2",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../data/uach.png\" alt=\"UACh\" width=\"180\">\n",
    "</p>\n",
    "\n",
    "# Hito 2 — Prototipo de Convolución\n",
    "\n",
    "Proyecto ACUS220 · Acústica Computacional con Python\n",
    "\n",
    "Este notebook implementa un prototipo funcional para auralización por convolución con una librería de presets de respuestas al impulso (IR). Permite generar una señal de entrada (o cargar una), seleccionar una IR (salas y un modelo escalonado tipo ‘Quetzal’), aplicar filtros simples y escuchar/visualizar el resultado, además de exportar a WAV.\n",
    "\n",
    "**Integrantes:** Carlos Duarte, Fernando Castillo, Vicente Alves, Antonio Duque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb1ed4",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "### 1.1 Problema\n",
    "\n",
    "### 1.2 Herramienta de convolución\n",
    "\n",
    "$ y(t) = x(t) * h(t) $\n",
    "\n",
    "### 1.3 Objetivos de este análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4132c",
   "metadata": {},
   "source": [
    "## 2. Análisis preliminar\n",
    "\n",
    "### 2.1 Generación de señales de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcf3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar por ejemplo un audio de un aplauso, graficar su forma de onda y espectrograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1ea5b",
   "metadata": {},
   "source": [
    "### 2.2 Características de la señal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analisis: duración, frecuencia, espectro de magnitud, etc......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73158a",
   "metadata": {},
   "source": [
    "## 3. Respuesta al impulso (IR)\n",
    "\n",
    "### 3.1 ¿Qué es IR?\n",
    "\n",
    "### 3.2 ¿Qué es la convolución?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e4b4f",
   "metadata": {},
   "source": [
    "## Qué hace este prototipo\n",
    "- Entradas: aplauso sintético, barrido senoidal o cargar WAV.\n",
    "- Presets de IR: salas (pequeña/mediana/gran sala) y un modelo escalonado ‘Pirámide (Quetzal)’.\n",
    "- Procesamiento: convolución FFT + normalización opcional + filtro simple (lowpass/highpass/bandpass).\n",
    "- Salida: reproductor de audio, forma de onda, espectrograma y opción de exportar WAV a `hito2/data/outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno listo.\n"
     ]
    }
   ],
   "source": [
    "import os, time, math, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import pyroomacoustics as pra\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "DATA_DIR = Path('data')\n",
    "IN_DIR = DATA_DIR / 'inputs'\n",
    "OUT_DIR = DATA_DIR / 'outputs'\n",
    "IN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Entorno listo.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbec1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilidades de audio y visualización\n",
    "def normalize_audio(x, peak=0.98):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.max(np.abs(x)) + 1e-12\n",
    "    return (x / m) * peak\n",
    "\n",
    "def resample_if_needed(x, sr, target_sr):\n",
    "    if target_sr is None or sr == target_sr:\n",
    "        return x, sr\n",
    "    g = math.gcd(int(sr), int(target_sr))\n",
    "    up = target_sr // g\n",
    "    down = sr // g\n",
    "    xr = signal.resample_poly(x, up, down)\n",
    "    return xr.astype(float), target_sr\n",
    "\n",
    "def load_audio(path, target_sr=None, mono=True):\n",
    "    x, sr = sf.read(path, always_2d=False)\n",
    "    if x.ndim > 1 and mono:\n",
    "        x = x.mean(axis=1)\n",
    "    x, sr = resample_if_needed(x, sr, target_sr)\n",
    "    return x.astype(float), sr\n",
    "\n",
    "def save_audio(path, x, sr):\n",
    "    sf.write(str(path), x, int(sr))\n",
    "\n",
    "def plot_waveform(x, sr, title='Señal'):\n",
    "    t = np.arange(len(x)) / sr\n",
    "    plt.figure()\n",
    "    plt.plot(t, x, lw=0.9)\n",
    "    plt.xlabel('Tiempo [s]')\n",
    "    plt.ylabel('Amplitud')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrogram(x, sr, title='Espectrograma'):\n",
    "    f, t, Sxx = signal.spectrogram(x, fs=sr, nperseg=1024, noverlap=512, scaling='spectrum')\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-12)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(t, f, Sxx_db, shading='auto', cmap='magma')\n",
    "    plt.ylabel('Frecuencia [Hz]')\n",
    "    plt.xlabel('Tiempo [s]')\n",
    "    plt.ylim(0, sr/2)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label='dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def play(x, sr):\n",
    "    display(Audio(x, rate=sr))\n",
    "\n",
    "def make_synthetic_clap(sr=48000, duration_s=0.12, decay=3.5, noise_level=0.3):\n",
    "    n = int(sr * duration_s)\n",
    "    x = np.zeros(n)\n",
    "    x[0] = 1.0  # impulso inicial\n",
    "    rn = np.random.randn(n)\n",
    "    env = np.exp(-np.linspace(0, decay, n))\n",
    "    x += noise_level * rn * env\n",
    "    return normalize_audio(x)\n",
    "\n",
    "def make_sine_sweep(sr=48000, dur_s=2.0, f0=20.0, f1=12000.0):\n",
    "    t = np.linspace(0, dur_s, int(sr*dur_s), endpoint=False)\n",
    "    x = signal.chirp(t, f0=f0, f1=f1, t1=dur_s, method='logarithmic')\n",
    "    win = signal.windows.tukey(len(x), alpha=0.1)\n",
    "    return normalize_audio(x*win)\n",
    "\n",
    "def butter_filter(x, sr, ftype='none', f_lo=200.0, f_hi=3000.0, order=4):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    nyq = 0.5 * sr\n",
    "    f_lo = max(10.0, min(f_lo, nyq*0.99))\n",
    "    f_hi = max(20.0, min(f_hi, nyq*0.99))\n",
    "    if ftype == 'none':\n",
    "        return x\n",
    "    if ftype == 'lowpass':\n",
    "        wn = min(f_hi/nyq, 0.999)\n",
    "        b, a = signal.butter(order, wn, btype='low', output='ba')\n",
    "    elif ftype == 'highpass':\n",
    "        wn = max(f_lo/nyq, 1e-4)\n",
    "        b, a = signal.butter(order, wn, btype='high', output='ba')\n",
    "    elif ftype == 'bandpass':\n",
    "        lo = max(1e-4, min(f_lo/nyq, 0.99))\n",
    "        hi = max(lo*1.01, min(f_hi/nyq, 0.999))\n",
    "        b, a = signal.butter(order, [lo, hi], btype='band', output='ba')\n",
    "    else:\n",
    "        return x\n",
    "    return signal.lfilter(b, a, x)\n",
    "\n",
    "def apply_ir(x, ir, normalize=True):\n",
    "    y = signal.fftconvolve(x, ir, mode='full')\n",
    "    return normalize_audio(y) if normalize else y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de IRs: sala (Pyroomacoustics) y estructura escalonada (‘Quetzal’)\n",
    "def pad_to_length(x, n):\n",
    "    if len(x) >= n:\n",
    "        return x[:n]\n",
    "    out = np.zeros(n)\n",
    "    out[:len(x)] = x\n",
    "    return out\n",
    "\n",
    "def simulate_room_ir(\n",
    "    sr=48000,\n",
    "    room_dim=(8.0, 5.0, 3.0),\n",
    "    absorption=0.2,\n",
    "    max_order=10,\n",
    "    src_pos=(2.0, 2.0, 1.5),\n",
    "    mic_pos=(6.0, 3.0, 1.5),\n",
    "    ir_length_s=1.2,\n",
    "):\n",
    "    materials = pra.Material(absorption)\n",
    "    room = pra.ShoeBox(room_dim, fs=sr, materials=materials, max_order=max_order)\n",
    "    room.add_source(src_pos)\n",
    "    mic_locs = np.array(mic_pos).reshape(-1, 1)\n",
    "    room.add_microphone_array(pra.MicrophoneArray(mic_locs, room.fs))\n",
    "    room.compute_rir()\n",
    "    ir = np.asarray(room.rir[0][0], dtype=float)\n",
    "    N = int(sr * ir_length_s)\n",
    "    ir = pad_to_length(ir, N)\n",
    "    return normalize_audio(ir)\n",
    "\n",
    "def stepped_structure_ir(\n",
    "    sr=48000,\n",
    "    base_delay_ms=6.0,   # primer retardo\n",
    "    step_delta_ms=1.2,   # incremento de retardo por eco\n",
    "    accel_ms=-0.03,      # curvatura temporal (chirp en tiempos)\n",
    "    num_steps=45,        # cantidad de ecos\n",
    "    decay=0.92,          # atenuación por paso\n",
    "    ir_length_s=1.4,\n",
    "):\n",
    "    delays_ms = []\n",
    "    for n in range(num_steps):\n",
    "        t = base_delay_ms + n * step_delta_ms + 0.5 * accel_ms * n * (n - 1)\n",
    "        if t >= 0:\n",
    "            delays_ms.append(t)\n",
    "    if not delays_ms:\n",
    "        return np.array([1.0])\n",
    "    max_delay_ms = max(delays_ms)\n",
    "    N = int(sr * ir_length_s)\n",
    "    L = max(N, int(sr * (max_delay_ms / 1000.0)) + sr // 10)\n",
    "    ir = np.zeros(L)\n",
    "    for i, t_ms in enumerate(delays_ms):\n",
    "        idx = int(round(sr * (t_ms / 1000.0)))\n",
    "        if idx < L:\n",
    "            ir[idx] += decay ** i\n",
    "    ir[0] += 0.05\n",
    "    ir = ir[:N] if N < len(ir) else ir\n",
    "    return normalize_audio(ir)\n",
    "\n",
    "def get_preset_ir(preset, sr):\n",
    "    preset = str(preset).lower().strip()\n",
    "    if preset.startswith('sala pequeña'):\n",
    "        ir = simulate_room_ir(sr=sr, room_dim=(4.0, 3.0, 2.5), absorption=0.45, max_order=8,\n",
    "                            src_pos=(1.2,1.0,1.2), mic_pos=(3.2,1.8,1.2), ir_length_s=1.0)\n",
    "        label = 'Sala pequeña'\n",
    "    elif preset.startswith('sala mediana'):\n",
    "        ir = simulate_room_ir(sr=sr, room_dim=(8.0, 5.5, 3.2), absorption=0.25, max_order=12,\n",
    "                            src_pos=(2.0,2.3,1.5), mic_pos=(6.0,3.1,1.5), ir_length_s=1.2)\n",
    "        label = 'Sala mediana'\n",
    "    elif 'hall' in preset or 'grande' in preset:\n",
    "        ir = simulate_room_ir(sr=sr, room_dim=(16.0, 11.0, 6.0), absorption=0.12, max_order=15,\n",
    "                            src_pos=(4.0,3.0,2.0), mic_pos=(12.0,7.0,2.5), ir_length_s=1.6)\n",
    "        label = 'Sala grande / Hall'\n",
    "    else:\n",
    "        ir = stepped_structure_ir(sr=sr)\n",
    "        label = 'Pirámide (Quetzal)'\n",
    "    return ir, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28955c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9b1f0070d74049905dd3d81cf5b141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Frecuencia de muestreo', options=(48000, 44100), value=480…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interfaz interactiva con ipywidgets\n",
    "# Controles\n",
    "sr_dd = widgets.Dropdown(options=[48000, 44100], value=48000, description='Frecuencia de muestreo')\n",
    "in_src = widgets.Dropdown(\n",
    "    options=['Aplauso (sintético)', 'Barrido senoidal (20 Hz–12 kHz)', 'Cargar WAV (carpeta inputs)'],\n",
    "    value='Aplauso (sintético)', description='Entrada'\n",
    ")\n",
    "wav_path = widgets.Text(value=str(IN_DIR / 'mi_audio.wav'), description='Ruta WAV', layout=widgets.Layout(width='50%'))\n",
    "\n",
    "preset_dd = widgets.Dropdown(\n",
    "    options=['Sala pequeña', 'Sala mediana', 'Sala grande / Hall', 'Pirámide (Quetzal) 🌪️'],\n",
    "    value='Sala mediana', description='Preajuste de IR'\n",
    ")\n",
    "\n",
    "# Filtro de coloración (post-EQ)\n",
    "eq_dd = widgets.Dropdown(options=['Ninguno', 'Pasa-bajos', 'Pasa-altos', 'Pasa-banda'], value='Ninguno', description='Filtro (posterior)')\n",
    "f_lo = widgets.FloatSlider(value=200.0, min=20.0, max=5000.0, step=10.0, description='Frecuencia baja [Hz]')\n",
    "f_hi = widgets.FloatSlider(value=3000.0, min=200.0, max=18000.0, step=10.0, description='Frecuencia alta [Hz]')\n",
    "normalize_ck = widgets.Checkbox(value=True, description='Normalizar')\n",
    "\n",
    "render_btn = widgets.Button(description='Procesar', button_style='primary')\n",
    "save_btn = widgets.Button(description='Exportar WAV', button_style='')\n",
    "out = widgets.Output()\n",
    "\n",
    "state = {'y': None, 'sr': None, 'label': None, 'busy': False}\n",
    "\n",
    "def _slug(s):\n",
    "    return ''.join(ch for ch in s.lower() if ch.isalnum() or ch in ('-', '_')).replace(' ', '_')\n",
    "\n",
    "def do_render(_=None):\n",
    "    if state.get('busy'):\n",
    "        return\n",
    "    state['busy'] = True\n",
    "    render_btn.disabled = True\n",
    "    try:\n",
    "        sr = int(sr_dd.value)\n",
    "        # Entrada\n",
    "        if in_src.value.startswith('Aplauso'):\n",
    "            x = make_synthetic_clap(sr=sr)\n",
    "        elif in_src.value.startswith('Barrido senoidal'):\n",
    "            x = make_sine_sweep(sr=sr)\n",
    "        else:\n",
    "            x, _sr = load_audio(wav_path.value, target_sr=sr)\n",
    "        # IR\n",
    "        ir, label = get_preset_ir(preset_dd.value, sr)\n",
    "        # Convolución\n",
    "        y = apply_ir(x, ir, normalize=normalize_ck.value)\n",
    "        # Post-EQ\n",
    "        eq_mode = eq_dd.value.lower()\n",
    "        if eq_mode != 'ninguno':\n",
    "            mode_map = {'pasa-bajos': 'lowpass', 'pasa-altos': 'highpass', 'pasa-banda': 'bandpass'}\n",
    "            y = butter_filter(y, sr, ftype=mode_map.get(eq_mode, 'none'), f_lo=f_lo.value, f_hi=f_hi.value, order=4)\n",
    "            if normalize_ck.value:\n",
    "                y = normalize_audio(y)\n",
    "        # Estado para exportar\n",
    "        state['y'] = y\n",
    "        state['sr'] = sr\n",
    "        state['label'] = label\n",
    "        # Mostrar\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            print(f'Entrada: {in_src.value} | IR: {label} | Frecuencia de muestreo: {sr} Hz')\n",
    "            print('— Señal de entrada')\n",
    "            play(x, sr)\n",
    "            print('— Respuesta al impulso (escuchar a bajo volumen)')\n",
    "            play(ir, sr)\n",
    "            print('— Señal de salida (convolución)')\n",
    "            play(y, sr)\n",
    "            plot_waveform(y, sr, title='Salida — forma de onda')\n",
    "            plot_spectrogram(y, sr, title='Salida — espectrograma')\n",
    "    finally:\n",
    "        state['busy'] = False\n",
    "        render_btn.disabled = False\n",
    "\n",
    "def do_save(_=None):\n",
    "    y = state.get('y'); sr = state.get('sr'); label = state.get('label') or 'out'\n",
    "    if y is None or sr is None:\n",
    "        with out: print('No hay resultado para exportar. Pulsa Procesar primero.')\n",
    "        return\n",
    "    fname = f'out_{_slug(label)}_{int(time.time())}.wav'\n",
    "    fpath = OUT_DIR / fname\n",
    "    save_audio(fpath, y, sr)\n",
    "    with out: print('Exportado:', fpath)\n",
    "\n",
    "# Evitar callbacks duplicados si se re-ejecuta la celda\n",
    "try:\n",
    "    render_btn._click_handlers.callbacks.clear()\n",
    "    save_btn._click_handlers.callbacks.clear()\n",
    "except Exception:\n",
    "    pass\n",
    "render_btn.on_click(do_render)\n",
    "save_btn.on_click(do_save)\n",
    "\n",
    "ui_top = widgets.HBox([sr_dd, in_src])\n",
    "ui_path = widgets.HBox([wav_path])\n",
    "ui_preset = widgets.HBox([preset_dd])\n",
    "ui_eq = widgets.HBox([eq_dd, f_lo, f_hi, normalize_ck])\n",
    "ui_btns = widgets.HBox([render_btn, save_btn])\n",
    "ui = widgets.VBox([ui_top, ui_path, ui_preset, ui_eq, ui_btns, out])\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
